const e="Pranav Rajpurkar",a="Our research aims to revolutionize clinical radiology by integrating advanced AI methodologies that enhance diagnostic accuracy and patient care. We have pioneered transformative techniques in uncertainty quantification, calibration, and self-supervised learning, which collectively improve the reliability and interpretability of AI models in medical imaging. By synthesizing our efforts in generalist AI models, innovative evaluation metrics, and synthetic data generation, we create a cohesive framework that addresses the multifaceted challenges of radiological practice. Our commitment to patient-centric communication ensures that these technological advancements are accessible and beneficial to both clinicians and patients alike. Ultimately, our innovations not only elevate the standards of radiology but also foster a more informed and engaged healthcare ecosystem.",n=JSON.parse(`[{"name":"Uncertainty Quantification and Calibration in AI for Clinical Radiology","synthesis":"Uncertainty quantification and calibration in AI for clinical radiology are critical for ensuring the reliability and accuracy of automated reporting systems. We introduced a two-stage framework for image-conditioned autocorrection that significantly enhances the reliability of medical reporting, achieving improved natural language generation scores. Our black-box detection method, RadFlag, effectively reduces hallucinations in generated reports, achieving a precision of 73% and decreasing hallucinations per report from 2.5 to 1.9. Additionally, our direct preference optimization method demonstrated a 3.2-4.8x reduction in hallucinated references to prior exams, underscoring the importance of maintaining clinical accuracy. Together, these innovations highlight the necessity for improved calibration and uncertainty estimation methods, as evidenced by our findings on the CheXzero model, which revealed poor calibration across external datasets.","papers":[{"title":"Image-Conditioned Autocorrection in Medical Reporting","authors":[{"full_name":"Arnold Caleb Asiimwe","normalized_name":"Arnold Asiimwe"},{"full_name":"Dídac Surís","normalized_name":"Didac Suris"},{"full_name":"Pranav Rajpurkar","normalized_name":"Pranav Rajpurkar"},{"full_name":"Carl Vondrick","normalized_name":"Carl Vondrick"}],"summary":"This paper addresses the critical issue of inaccuracies in radiological reports, proposing a novel two-stage framework for image-conditioned autocorrection. The methodology involves introducing diverse errors into reports from the MIMIC-CXR dataset and subsequently detecting and correcting these errors, significantly enhancing the reliability of automated medical reporting systems. Empirical results demonstrate that the proposed approach improves natural language generation scores and effectively corrects errors in generated reports, showcasing its potential as a guardrail for automated report generation.","weight":0.85,"role":"primary_research","file_path":"pdfs/2412.02971v1.pdf"},{"title":"RadFlag: A Black-Box Hallucination Detection Method for Medical Vision Language Models","authors":[{"full_name":"Serena Zhang","normalized_name":"Serena Zhang"},{"full_name":"Sraavya Sambara","normalized_name":"Sraavya Sambara"},{"full_name":"Oishi Banerjee","normalized_name":"Oishi Banerjee"},{"full_name":"Julian N. Acosta","normalized_name":"Julian Acosta"},{"full_name":"L. John Fahrner","normalized_name":"John Fahrner"},{"full_name":"Pranav Rajpurkar","normalized_name":"Pranav Rajpurkar"}],"summary":"This paper addresses the critical issue of hallucinations in radiology report generation by introducing RadFlag, a black-box detection method. The key innovation lies in a sampling-based flagging technique that identifies hallucinated claims by assessing their consistency across multiple generated reports. Empirical results demonstrate that RadFlag achieves a precision of 73% in flagging hallucinations while effectively reducing the number of hallucinations per report from 2.5 to 1.9.","weight":0.85,"role":"primary_research","file_path":"pdfs/2411.00299v2.pdf"},{"title":"Direct Preference Optimization for Suppressing Hallucinated Prior Exams in Radiology Report Generation","authors":[{"full_name":"Oishi Banerjee","normalized_name":"Oishi Banerjee"},{"full_name":"Hong-Yu Zhou","normalized_name":"Hong Yu Zhou"},{"full_name":"Subathra Adithan","normalized_name":"Subathra Adithan"},{"full_name":"Stephen Kwak","normalized_name":"Stephen Kwak"},{"full_name":"Kay Wu","normalized_name":"Kay Wu"},{"full_name":"Pranav Rajpurkar","normalized_name":"Pranav Rajpurkar"}],"summary":"This paper addresses the problem of hallucinations in generative vision-language models (VLMs) used for radiology report generation, specifically focusing on the hallucination of prior exams. The authors propose a novel method based on direct preference optimization (DPO) to suppress these unwanted behaviors while maintaining clinical accuracy. Empirical results demonstrate a significant reduction in hallucinated references to prior exams, achieving a 3.2-4.8x decrease in lines hallucinating prior exams without compromising the model's performance on clinical accuracy metrics.","weight":0.85,"role":"primary_research","file_path":"pdfs/2406.06496v2.pdf"},{"title":"Calibration and Uncertainty Estimation Challenges in Self-Supervised Chest X-ray Pathology Classification Models","authors":[{"full_name":"Jenny Xu","normalized_name":"Jenny Xu"},{"full_name":"Pranav Rajpurkar","normalized_name":"Pranav Rajpurkar"}],"summary":"This paper addresses the critical issue of uncertainty quantification in AI systems for clinical radiology, specifically focusing on the calibration of the CheXzero model for chest X-ray pathology detection. The authors evaluate two uncertainty estimation methods, Maximum Softmax Probabilities (MSP) and Monte Carlo Dropout, revealing poor calibration with Expected Calibration Error (ECE) scores ranging from 0.12 to 0.41 across external datasets, and a lack of correlation between prediction accuracy and uncertainty scores. These findings underscore the necessity for improved uncertainty quantification methods in AI-assisted clinical decision-making.","weight":0.8,"role":"primary_research","file_path":"pdfs/160_Calibration_and_Uncertaint.pdf"},{"title":"Reimbursement in the age of generalist radiology artificial intelligence","authors":[{"full_name":"Siddhant Dogra","normalized_name":"Siddhant Dogra"},{"full_name":"Ezequiel Silva III","normalized_name":"Ezequiel Silva"},{"full_name":"Pranav Rajpurkar","normalized_name":"Pranav Rajpurkar"}],"summary":"This paper addresses the challenges posed by generalist radiology artificial intelligence (GRAI) to existing healthcare reimbursement frameworks, highlighting the inadequacy of current coding, valuation, and coverage policies. The authors propose that GRAI's multi-task capabilities necessitate a reevaluation of reimbursement strategies to ensure effective integration into clinical practice. Key findings indicate that as GRAI tools emerge, they will require distinct reimbursement pathways that differ from those used for narrow AI solutions, emphasizing the need for adaptive coding and valuation methods.","weight":0.8,"role":"primary_research","file_path":"pdfs/s41746-024-01352-w.pdf"}]},{"name":"Generalist AI Models for Enhanced Medical Image Interpretation","synthesis":"The advancement of generalist AI models for medical image interpretation is crucial for enhancing diagnostic accuracy and personalizing patient care. Our work introduces MedVersa, a generalist learner that outperforms specialist models by over 10% across nine tasks, showcasing its versatility in medical image analysis. Additionally, the large mixture-of-modality-experts model (MOME) achieved an AUROC of 0.913, significantly reducing unnecessary biopsies and demonstrating comparable performance to experienced radiologists. We also explored the adaptation of generalist models like SAM through innovative fine-tuning methods, achieving an average Dice score of 85.34, which highlights the potential of these models in medical applications. Collectively, these approaches illustrate how generalist AI can be effectively tailored to meet the diverse challenges of medical imaging, paving the way for improved clinician-AI collaboration.","papers":[{"title":"A Generalist Learner for Multifaceted Medical Image Interpretation","authors":[{"full_name":"Hong-Yu Zhou, PhD","normalized_name":"Hong Yu Zhou"},{"full_name":"Subathra Adithan, MD","normalized_name":"Subathra Adithan"},{"full_name":"Julián Nicolás Acosta, MD","normalized_name":"Julian Nicolas Acosta"},{"full_name":"Eric J. Topol, MD","normalized_name":"Eric Topol"},{"full_name":"Pranav Rajpurkar, PhD","normalized_name":"Pranav Rajpurkar"}],"summary":"This paper addresses the limitation of current medical AI systems, which are often restricted to narrow applications. The key innovation is MedVersa, a generalist learner that utilizes a large language model as a learnable orchestrator to enable flexible learning and tasking for medical image interpretation. Empirical results show that MedVersa achieves state-of-the-art performance in nine tasks, outperforming specialist models by over 10% in some cases, demonstrating its potential for comprehensive medical image analysis.","weight":0.9,"role":"primary_research","file_path":"pdfs/2405.07988v1.pdf"},{"title":"Towards Non-invasive and Personalized Management of Breast Cancer Patients from Multiparametric MRI via A Large Mixture-of-Modality-Experts Model","authors":[{"full_name":"Luyang Luo","normalized_name":"Luyang Luo"},{"full_name":"Mingxiang Wu","normalized_name":"Mingxiang Wu"},{"full_name":"Mei Li","normalized_name":"Mei Li"},{"full_name":"Yi Xin","normalized_name":"Yi Xin"},{"full_name":"Qiong Wang","normalized_name":"Qiong Wang"},{"full_name":"Varut Vardhanabhuti","normalized_name":"Varut Vardhanabhuti"},{"full_name":"Winnie CW Chu","normalized_name":"Winnie CW Chu"},{"full_name":"Zhenhui Li","normalized_name":"Zhenhui Li"},{"full_name":"Juan Zhou","normalized_name":"Juan Zhou"},{"full_name":"Pranav Rajpurkar","normalized_name":"Pranav Rajpurkar"},{"full_name":"Hao Chen","normalized_name":"Hao Chen"}],"summary":"This paper addresses the challenge of integrating multiparametric MRI data for breast cancer diagnosis, which has been limited by reliance on single sequences in AI studies. The authors introduce a large mixture-of-modality-experts model (MOME) that effectively combines various MRI modalities, achieving an AUROC of 0.913 and significantly reducing unnecessary biopsies for BI-RADS 4 patients. MOME demonstrates comparable performance to experienced radiologists, indicating its potential for personalized breast cancer management.","weight":0.9,"role":"primary_research","file_path":"pdfs/2408.12606v2.pdf"},{"title":"Heterogeneity and predictors of the effects of AI assistance on radiologists","authors":[{"full_name":"Feiyang Yu","normalized_name":"Feiyang Yu"},{"full_name":"Alex Moehring","normalized_name":"Alex Moehring"},{"full_name":"Oishi Banerjee","normalized_name":"Oishi Banerjee"},{"full_name":"Tobias Salz","normalized_name":"Tobias Salz"},{"full_name":"Nikhil Agarwal","normalized_name":"Nikhil Agarwal"},{"full_name":"Pranav Rajpurkar","normalized_name":"Pranav Rajpurkar"}],"summary":"This study addresses the heterogeneous effects of AI assistance on 140 radiologists performing 15 chest X-ray diagnostic tasks. The key innovation lies in identifying that conventional experience-based predictors, such as years of experience and familiarity with AI tools, do not reliably forecast the impact of AI assistance. The findings reveal that AI errors significantly influence treatment outcomes, emphasizing the need for personalized clinician-AI collaboration strategies.","weight":0.85,"role":"primary_research","file_path":"pdfs/s41591-024-02850-w.pdf"},{"title":"A Perspective for Adapting Generalist AI to Specialized Medical AI Applications and Their Challenges","authors":[{"full_name":"Zifeng Wang","normalized_name":"Zifeng Wang"},{"full_name":"Hanyin Wang","normalized_name":"Hanyin Wang"},{"full_name":"Benjamin Danek","normalized_name":"Benjamin Danek"},{"full_name":"Ying Li","normalized_name":"Ying Li"},{"full_name":"Christina Mack","normalized_name":"Christina Mack"},{"full_name":"Luk Arbuckle","normalized_name":"Luk Arbuckle"},{"full_name":"Devyani Biswal","normalized_name":"Devyani Biswal"},{"full_name":"Hoifung Poon","normalized_name":"Hoifung Poon"},{"full_name":"Yajuan Wang","normalized_name":"Yajuan Wang"},{"full_name":"Pranav Rajpurkar","normalized_name":"Pranav Rajpurkar"},{"full_name":"Jimeng Sun","normalized_name":"Jimeng Sun"}],"summary":"This paper addresses the challenge of adapting generalist Large Language Models (LLMs) for specialized medical applications. The authors propose a three-step framework that includes modeling, optimization, and system engineering to enhance the performance of medical AI applications. Key findings indicate that tailored adaptations significantly improve the accuracy and reliability of LLMs in medical contexts, addressing issues such as hallucinations and compliance with medical standards.","weight":0.85,"role":"primary_research","file_path":"pdfs/2411.00024v3.pdf"},{"title":"Adapting Segment Anything Models to Medical Imaging via Fine-Tuning without Domain Pretraining","authors":[{"full_name":"Kevin Li","normalized_name":"Kevin Li"},{"full_name":"Pranav Rajpurkar","normalized_name":"Pranav Rajpurkar"}],"summary":"This paper addresses the challenge of adapting the Segment Anything Model (SAM) for medical image segmentation without relying on domain-specific pre-training. The authors introduce a novel fine-tuning method called LoRaMedNet, which combines Low-Rank Adaptation with a ConvNet prediction head, demonstrating that SAM can achieve superior performance on medical tasks compared to MedSAM, a model specifically trained on medical datasets. Empirical results indicate that LoRaMedNet-adapted SAM outperforms existing methods, achieving an average Dice score of 85.34, highlighting the potential of generalist models in medical applications.","weight":0.8,"role":"primary_research","file_path":"pdfs/22_Adapting_Segment_Anything_M.pdf"},{"title":"Evaluating General Vision-Language Models for Clinical Medicine","authors":[{"full_name":"Yixing Jiang","normalized_name":"Yixing Jiang"},{"full_name":"Jesutofunmi A. Omiye","normalized_name":"Jesutofunmi Omiye"},{"full_name":"Cyril Zakka","normalized_name":"Cyril Zakka"},{"full_name":"Michael Moor","normalized_name":"Michael Moor"},{"full_name":"Haiwen Gui","normalized_name":"Haiwen Gui"},{"full_name":"Shayan Alipour","normalized_name":"Shayan Alipour"},{"full_name":"Seyed Shahabeddin Mousavi","normalized_name":"Seyed Shahabeddin Mousavi"},{"full_name":"Jonathan H. Chen","normalized_name":"Jonathan Chen"},{"full_name":"Pranav Rajpurkar","normalized_name":"Pranav Rajpurkar"},{"full_name":"Roxana Daneshjou","normalized_name":"Roxana Daneshjou"}],"summary":"This paper addresses the limitations of large multimodal models (LMMs) like GPT-4V in clinical medicine, particularly in gastroenterology, radiology, and dermatology. The authors benchmarked GPT-4V's diagnostic capabilities using robust datasets and found significant performance deficits compared to existing models, with macro-average precision, recall, and F1-scores as low as 6.8% in gastroenterology and 6.2% in dermatology. The study highlights the model's bias against darker skin tones and calls for further research into improving LMMs for medical applications.","weight":0.3,"role":"primary_research","file_path":"pdfs/2024.04.12.24305744v2.full.pdf"}]},{"name":"Innovative Evaluation Metrics for AI-Generated Radiology Reports","synthesis":"The evaluation of AI-generated radiology reports is critical for ensuring diagnostic accuracy and clinical relevance in medical imaging. We introduced ReXrank, a public leaderboard that established a comprehensive evaluation framework, demonstrating that our model outperformed others with significant improvements across diverse datasets. Complementing this, FineRadScore utilized Large Language Models to provide line-by-line corrections, achieving alignment with radiologist assessments and surpassing existing metrics in accuracy and clinical relevance. Additionally, HeadCT-ONE enhanced evaluation granularity by incorporating ontology-normalized entity extraction, leading to improved identification of clinically significant errors. Together, these methodologies highlight the importance of innovative metrics in bridging the gap between AI capabilities and clinical expectations.","papers":[{"title":"ReXrank: A Public Leaderboard for AI-Powered Radiology Report Generation","authors":[{"full_name":"Xiaoman Zhang","normalized_name":"Xiaoman Zhang"},{"full_name":"Hong-Yu Zhou","normalized_name":"Hongyu Zhou"},{"full_name":"Xiaoli Yang","normalized_name":"Xiaoli Yang"},{"full_name":"Oishi Banerjee","normalized_name":"Oishi Banerjee"},{"full_name":"Julián N. Acosta","normalized_name":"Julian Acosta"},{"full_name":"Josh Miller","normalized_name":"Josh Miller"},{"full_name":"Ouwen Huang","normalized_name":"Ouwen Huang"},{"full_name":"Pranav Rajpurkar","normalized_name":"Pranav Rajpurkar"}],"summary":"This paper addresses the lack of standardized benchmarks for evaluating AI-driven radiology report generation models, particularly for chest X-rays. The authors introduce ReXrank, a public leaderboard that utilizes a comprehensive evaluation framework with diverse datasets and multiple metrics to assess model performance. Key findings indicate that MedVersa outperforms other models across various datasets, demonstrating the effectiveness of the proposed evaluation approach.","weight":0.9,"role":"primary_research","file_path":"pdfs/2411.15122v1.pdf"},{"title":"FineRadScore: A Radiology Report Line-by-Line Evaluation Technique Generating Corrections with Severity Scores","authors":[{"full_name":"Alyssa Huang","normalized_name":"Alyssa Huang"},{"full_name":"Oishi Banerjee","normalized_name":"Oishi Banerjee"},{"full_name":"Kay Wu","normalized_name":"Kay Wu"},{"full_name":"Eduardo Pontes Reis","normalized_name":"Eduardo Reis"},{"full_name":"Pranav Rajpurkar","normalized_name":"Pranav Rajpurkar"}],"summary":"This paper addresses the challenge of evaluating AI-generated chest X-ray (CXR) reports, which traditionally relies on time-consuming radiologist annotations. The authors introduce FineRadScore, an automated evaluation metric utilizing Large Language Models (LLMs) to provide line-by-line corrections and error severity ratings for generated reports. Empirical results demonstrate that FineRadScore aligns closely with radiologist assessments, outperforming existing automated metrics in both correction accuracy and clinical relevance.","weight":0.85,"role":"primary_research","file_path":"pdfs/2405.20613v2.pdf"},{"title":"HeadCT-ONE: Enabling Granular and Controllable Automated Evaluation of Head CT Radiology Report Generation","authors":[{"full_name":"Julián N. Acosta, MD","normalized_name":"Julian Acosta"},{"full_name":"Xiaoman Zhang, PhD","normalized_name":"Xiaoman Zhang"},{"full_name":"Siddhant Dogra, MD","normalized_name":"Siddhant Dogra"},{"full_name":"Hong-Yu Zhou, PhD","normalized_name":"Hongyu Zhou"},{"full_name":"Sam Payabvash, MD","normalized_name":"Sam Payabvash"},{"full_name":"Guido J. Falcone, MD, ScD, MPH","normalized_name":"Guido Falcone"},{"full_name":"Eric K. Oermann, MD","normalized_name":"Eric Oermann"},{"full_name":"Pranav Rajpurkar, PhD","normalized_name":"Pranav Rajpurkar"}],"summary":"This paper addresses the challenge of evaluating AI-generated head CT radiology reports, proposing HeadCT-ONE, a novel metric that enhances existing evaluation methods by incorporating ontology-normalized entity and relation extraction. The methodology involves comparing normalized entities and relations, allowing for customizable weighting of different entity types, which significantly improves the identification of clinically significant errors. Empirical results demonstrate that HeadCT-ONE outperforms traditional metrics, achieving higher accuracy in distinguishing between normal and abnormal reports.","weight":0.85,"role":"primary_research","file_path":"pdfs/2409.13038v1.pdf"},{"title":"Uncovering Knowledge Gaps in Radiology Report Generation Models through Knowledge Graphs","authors":[{"full_name":"Xiaoman Zhang","normalized_name":"Xiaoman Zhang"},{"full_name":"Julián N. Acosta","normalized_name":"Julian Acosta"},{"full_name":"Hong-Yu Zhou","normalized_name":"Hongyu Zhou"},{"full_name":"Pranav Rajpurkar","normalized_name":"Pranav Rajpurkar"}],"summary":"This paper addresses the limitations of existing evaluation methods for AI-generated radiology reports, which fail to capture the models' understanding of radiological images. The authors introduce ReXKG, a system that constructs a comprehensive radiology knowledge graph and propose three novel metrics to evaluate AI models' performance. The study reveals that while generalist models show broader coverage of essential entities, they still lack the depth and detail found in human-written reports, particularly in describing medical devices and providing quantified measurements.","weight":0.8,"role":"primary_research","file_path":"pdfs/2408.14397v1.pdf"}]},{"name":"Synthetic Data Generation and Its Impact on Medical Imaging","synthesis":"The significance of synthetic data generation in medical imaging lies in its potential to address data scarcity and privacy concerns, which are critical barriers to the advancement of AI models. We introduced innovative methodologies such as generative models, including GANs and diffusion models, which have demonstrated substantial improvements in classification and segmentation tasks, with accuracy enhancements observed when synthetic images are integrated into training datasets. Our work on the ReXErr methodology further complements this by generating clinically meaningful errors in diagnostic reports, effectively mimicking real-world inaccuracies and providing valuable resources for model evaluation. Additionally, the FactCheXcker framework significantly mitigates measurement hallucinations in report generation, achieving a remarkable 94% reduction in errors across multiple models, thereby enhancing clinical assessment accuracy. Collectively, these approaches underscore the importance of collaborative frameworks, like the MAIDA initiative, which fosters global data sharing to enrich the diversity and reliability of medical imaging datasets.","papers":[{"title":"Video Pretraining Advances 3D Deep Learning on Chest CT Tasks","authors":[{"full_name":"Alexander Ke","normalized_name":"Alexander Ke"},{"full_name":"Shih-Cheng Huang","normalized_name":"Shih Cheng Huang"},{"full_name":"Chloe O’Connell","normalized_name":"Chloe OConnell"},{"full_name":"Micha l Klimont","normalized_name":"Micha l Klimont"},{"full_name":"Serena Yeung","normalized_name":"Serena Yeung"},{"full_name":"Pranav Rajpurkar","normalized_name":"Pranav Rajpurkar"}],"summary":"This study addresses the challenge of limited data in 3D medical imaging tasks by exploring the effectiveness of video pretraining for enhancing model performance. The key innovation is the application of large-scale video datasets to pretrain 3D models, which significantly improves their performance on chest CT tasks, as evidenced by a mean AUC increase of 0.146 on pulmonary embolism detection. The findings suggest that video pretraining outperforms traditional in-domain pretraining methods, particularly in data-scarce scenarios.","weight":0.9,"role":"primary_research","file_path":"pdfs/ke24a.pdf"},{"title":"FactCheXcker: Mitigating Measurement Hallucinations in Chest X-ray Report Generation Models","authors":[{"full_name":"Alice Heiman","normalized_name":"Alice Heiman"},{"full_name":"Xiaoman Zhang, PhD","normalized_name":"Xiaoman Zhang"},{"full_name":"Emma Chen, MS","normalized_name":"Emma Chen"},{"full_name":"Sung Eun Kim, MD","normalized_name":"Sung Eun Kim"},{"full_name":"Pranav Rajpurkar, PhD","normalized_name":"Pranav Rajpurkar"}],"summary":"This paper addresses the problem of measurement hallucinations in radiology report generation models, which can lead to inaccurate clinical assessments. The key innovation is the FactCheXcker framework, which utilizes a modular query-code-update approach to improve measurement accuracy without retraining existing models. Empirical results demonstrate a significant average improvement of 94% in reducing measurement hallucinations, as measured by mean absolute error, across 11 medical report-generation models.","weight":0.9,"role":"primary_research","file_path":"pdfs/2411.18672v1.pdf"},{"title":"Generating Synthetic Data for Medical Imaging","authors":[{"full_name":"Lennart R. Koetzier","normalized_name":"Lennart Koetzier"},{"full_name":"Jie Wu","normalized_name":"Jie Wu"},{"full_name":"Domenico Mastrodicasa","normalized_name":"Domenico Mastrodicasa"},{"full_name":"Aline Lutz","normalized_name":"Aline Lutz"},{"full_name":"Matthew Chung","normalized_name":"Matthew Chung"},{"full_name":"W. Adam Koszek","normalized_name":"W. Adam Koszek"},{"full_name":"Jayanth Pratap","normalized_name":"Jayanth Pratap"},{"full_name":"Akshay S. Chaudhari","normalized_name":"Akshay Chaudhari"},{"full_name":"Pranav Rajpurkar","normalized_name":"Pranav Rajpurkar"},{"full_name":"Matthew P. Lungren","normalized_name":"Matthew Lungren"},{"full_name":"Martin J. Willemink","normalized_name":"Martin Willemink"}],"summary":"This paper addresses the challenge of data scarcity and privacy issues in medical imaging, which hinder the development of AI models. The authors propose the use of synthetic data generated by AI models as a solution, highlighting innovations in generative models such as GANs and diffusion models. Empirical findings indicate that synthetic data can significantly enhance the performance of AI models in classification and segmentation tasks, with quantitative results showing improved accuracy when synthetic images are included in training datasets.","weight":0.85,"role":"primary_research","file_path":"pdfs/koetzier-et-al-2024-generating-synthetic-data-for-medical-imaging.pdf"},{"title":"ReXErr: Synthesizing Clinically Meaningful Errors in Diagnostic Radiology Reports","authors":[{"full_name":"Vishwanatha M. Rao","normalized_name":"Vishwanatha Rao"},{"full_name":"Serena Zhang","normalized_name":"Serena Zhang"},{"full_name":"Julian N. Acosta","normalized_name":"Julian Acosta"},{"full_name":"Subathra Adithan","normalized_name":"Subathra Adithan"},{"full_name":"Pranav Rajpurkar","normalized_name":"Pranav Rajpurkar"}],"summary":"This paper addresses the challenge of errors in radiology reports, both human-written and AI-generated. The key innovation is the ReXErr methodology, which utilizes Large Language Models to generate representative errors in chest X-ray reports, ensuring clinical plausibility. Empirical findings indicate that ReXErr effectively mimics real-world errors, providing a valuable resource for developing and evaluating report correction algorithms.","weight":0.85,"role":"primary_research","file_path":"pdfs/rao-et-al-2024-rexerr-synthesizing-clinically-meaningful-errors-in-diagnostic-radiology-reports.pdf"},{"title":"The MAIDA initiative: establishing a framework for global medical-imaging data sharing","authors":[{"full_name":"Agustina Saenz","normalized_name":"Agustina Saenz"},{"full_name":"Emma Chen","normalized_name":"Emma Chen"},{"full_name":"Henrik Marklund","normalized_name":"Henrik Marklund"},{"full_name":"Pranav Rajpurkar","normalized_name":"Pranav Rajpurkar"}],"summary":"The MAIDA initiative addresses the critical shortage of diverse public datasets necessary for training and validating AI algorithms in medical imaging. It introduces a collaborative framework for global data sharing, focusing on curating comprehensive datasets from various clinical settings to enhance the generalizability and reliability of AI models. Initial findings indicate that engaging local champions and standardizing data-sharing protocols significantly improve data collection and de-identification processes across institutions.","weight":0.8,"role":"primary_research","file_path":"pdfs/PIIS2589750023002224.pdf"}]},{"name":"Advancements in Self-Supervised Learning for Diagnostic Accuracy","synthesis":"Advancements in self-supervised learning are pivotal for enhancing diagnostic accuracy in medical imaging, particularly in the context of limited labeled datasets. Our exploration of self-supervised techniques, exemplified by CheXzero, demonstrates a significant leap in performance, outperforming traditional algorithms and human radiologists in diagnosing rare diseases. Empirical findings indicate that our retrieval-based approach, X-REM, improves report generation accuracy by 70%, showcasing the effectiveness of multimodal image-text matching. These methodologies not only complement each other but also highlight the potential of interdisciplinary collaboration in refining AI applications in healthcare. Collectively, our contributions underscore the transformative impact of self-supervised learning on diagnostic processes, paving the way for more robust and efficient medical AI systems.","papers":[{"title":"Pixels and Pitfalls: Building Robust Artificial Intelligence for Medical Imaging","authors":[{"full_name":"Pranav Rajpurkar, Ph.D.","normalized_name":"Pranav Rajpurkar"},{"full_name":"Andrew L. Beam, Ph.D.","normalized_name":"Andrew Beam"},{"full_name":"Arjun K. Manrai, Ph.D.","normalized_name":"Arjun Manrai"}],"summary":"This paper addresses the challenges and advancements in applying artificial intelligence (AI) to medical imaging, particularly focusing on the evolution from early models like CheXNet to more advanced systems such as CheXzero. The key innovation discussed is the shift towards self-supervised learning techniques that reduce reliance on labeled datasets, with empirical findings indicating significant improvements in diagnostic accuracy and efficiency. The authors advocate for interdisciplinary collaboration and open access to medical data to enhance AI model development and deployment.","weight":0.85,"role":"primary_research","file_path":"pdfs/AIp2400803.pdf"},{"title":"Multimodal Image-Text Matching Improves Retrieval-based Chest X-Ray Report Generation","authors":[{"full_name":"Jaehwan Jeong","normalized_name":"Jaehwan Jeong"},{"full_name":"Katherine Tian","normalized_name":"Katherine Tian"},{"full_name":"Andrew Li","normalized_name":"Andrew Li"},{"full_name":"Sina Hartung","normalized_name":"Sina Hartung"},{"full_name":"Fardad Behzadi","normalized_name":"Fardad Behzadi"},{"full_name":"Juan Calle","normalized_name":"Juan Calle"},{"full_name":"David Osayande","normalized_name":"David Osayande"},{"full_name":"Michael Pohlen","normalized_name":"Michael Pohlen"},{"full_name":"Subathra Adithan","normalized_name":"Subathra Adithan"},{"full_name":"Pranav Rajpurkar","normalized_name":"Pranav Rajpurkar"}],"summary":"This paper addresses the challenge of generating clinically accurate radiology reports from chest X-ray images, which often suffer from incoherence and irrelevance in existing methods. The authors introduce Contrastive X-Ray REport Match (X-REM), a novel retrieval-based approach that utilizes an image-text matching score to enhance report retrieval accuracy. Empirical results demonstrate that X-REM significantly outperforms prior models, achieving higher clinical and natural language metrics, and increasing the number of zero-error reports by 70%.","weight":0.85,"role":"primary_research","file_path":"pdfs/jeong24a.pdf"},{"title":"Comparative Advantage of Humans vs AI in the Long Tail","authors":[{"full_name":"Nikhil Agarwal","normalized_name":"Nikhil Agarwal"},{"full_name":"Ray Huang","normalized_name":"Ray Huang"},{"full_name":"Alex Moehring","normalized_name":"Alex Moehring"},{"full_name":"Pranav Rajpurkar","normalized_name":"Pranav Rajpurkar"},{"full_name":"Tobias Salz","normalized_name":"Tobias Salz"},{"full_name":"Feiyang Yu","normalized_name":"Feiyang Yu"}],"summary":"This paper investigates the comparative performance of zero-shot learning algorithms and human radiologists in diagnosing rare diseases using chest X-rays. The key innovation is the introduction of CheXzero, a self-supervised learning algorithm, which is compared against human performance and the CheXpert algorithm. The findings reveal that while humans still excel in certain pathologies, CheXzero demonstrates superior performance overall, particularly in the long tail of diseases, suggesting a diminishing advantage for human radiologists in this domain.","weight":0.8,"role":"primary_research","file_path":"pdfs/ComparativeAdvantageOfHumansVsAIIn_preview.pdf"},{"title":"Cell morphological representations of genes enhance prediction of drug targets","authors":[{"full_name":"Niveditha S. Iyer","normalized_name":"Niveditha Iyer"},{"full_name":"Daniel J. Michael","normalized_name":"Daniel Michael"},{"full_name":"S-Y Gordon Chi","normalized_name":"S-Y Chi"},{"full_name":"John Arevalo","normalized_name":"John Arevalo"},{"full_name":"Srinivas Niranj Chandrasekaran","normalized_name":"Srinivas Chandrasekaran"},{"full_name":"Anne E. Carpenter","normalized_name":"Anne Carpenter"},{"full_name":"Pranav Rajpurkar","normalized_name":"Pranav Rajpurkar"},{"full_name":"Shantanu Singh","normalized_name":"Shantanu Singh"}],"summary":"This study addresses the challenge of identifying potential protein targets for candidate drugs in the drug discovery process. The key innovation is the integration of gene morphological profiles into a transformer-based machine learning model, which significantly improves the accuracy of predicting gene-compound interactions. Empirical results show that the model outperforms baseline methods, particularly in predicting targets for previously unseen compounds, although it struggles with novel genes due to the diversity of protein targets.","weight":0.8,"role":"primary_research","file_path":"pdfs/2024.06.08.598076v1.full.pdf"}]},{"name":"Patient-Centric Communication and Accessibility in Radiology","synthesis":"Patient-Centric Communication and Accessibility in Radiology is crucial for enhancing patient understanding and engagement in their healthcare journey. We introduced the ReXplain system, which effectively simplifies complex radiology reports using a large language model and anatomical image segmentation, demonstrating a significant improvement in patient comprehension and satisfaction. Our findings indicate that this approach can simulate one-on-one consultations, potentially transforming patient interactions with radiological information. Additionally, the ReXamine-Global framework addresses inconsistencies in report generation metrics, revealing that many established evaluation methods are overly sensitive to stylistic differences, thus highlighting the need for more robust metrics. Together, these innovations underscore the importance of integrating AI and patient-centric methodologies to improve communication and accessibility in radiology.","papers":[{"title":"Implications of Race Adjustment in Lung-Function Equations","authors":[{"full_name":"James A. Diao","normalized_name":"Diao James"},{"full_name":"Yixuan He","normalized_name":"He Yixuan"},{"full_name":"Rohan Khazanchi","normalized_name":"Khazanchi Rohan"},{"full_name":"Max Jordan Nguemeni Tiako","normalized_name":"Tiako Max Nguemeni"},{"full_name":"Jonathan I. Witonsky","normalized_name":"Witonsky Jonathan"},{"full_name":"Emma Pierson","normalized_name":"Pierson Emma"},{"full_name":"Pranav Rajpurkar","normalized_name":"Rajpurkar Pranav"},{"full_name":"Jennifer R. Elhawary","normalized_name":"Elhawary Jennifer"},{"full_name":"Luke Melas-Kyriazi","normalized_name":"Melas-Kyriazi Luke"},{"full_name":"Albert Yen","normalized_name":"Yen Albert"},{"full_name":"Alicia R. Martin","normalized_name":"Martin Alicia"},{"full_name":"Sean Levy","normalized_name":"Levy Sean"},{"full_name":"Chirag J. Patel","normalized_name":"Patel Chirag"},{"full_name":"Maha Farhat","normalized_name":"Farhat Maha"},{"full_name":"Luisa N. Borrell","normalized_name":"Borrell Luisa"},{"full_name":"Michael H. Cho","normalized_name":"Cho Michael"},{"full_name":"Edwin K. Silverman","normalized_name":"Silverman Edwin"},{"full_name":"Esteban G. Burchard","normalized_name":"Burchard Esteban"},{"full_name":"Arjun K. Manrai","normalized_name":"Manrai Arjun"}],"summary":"This study addresses the research problem of the implications of race adjustment in lung-function testing, specifically comparing race-based and race-neutral equations. The key innovation is the introduction of race-neutral equations (GLI-Global) derived from extensive longitudinal data, which were compared to the race-based GLI-2012 equations. The findings indicate significant reclassifications in ventilatory impairment and disability compensation, with millions affected, highlighting disparities based on race.","weight":0.85,"role":"primary_research","file_path":"pdfs/nihms-2003202.pdf"},{"title":"ReXamine-Global: A Framework for Uncovering Inconsistencies in Radiology Report Generation Metrics","authors":[{"full_name":"Oishi Banerjee","normalized_name":"Banerjee Oishi"},{"full_name":"Agustina Saenz","normalized_name":"Saenz Agustina"},{"full_name":"Kay Wu","normalized_name":"Wu Kay"},{"full_name":"Warren Clements","normalized_name":"Clements Warren"},{"full_name":"Adil Zia","normalized_name":"Zia Adil"},{"full_name":"Dominic Buensalido","normalized_name":"Buensalido Dominic"},{"full_name":"Helen Kavnoudias","normalized_name":"Kavnoudias Helen"},{"full_name":"Alain S. Abi-Ghanem","normalized_name":"Abi-Ghanem Alain"},{"full_name":"Nour El Ghawi","normalized_name":"El Ghawi Nour"},{"full_name":"Cibele Luna","normalized_name":"Luna Cibele"},{"full_name":"Patricia Castillo","normalized_name":"Castillo Patricia"},{"full_name":"Khaled Al-Surimi","normalized_name":"Al-Surimi Khaled"},{"full_name":"Rayyan A. Daghistani","normalized_name":"Daghistani Rayyan"},{"full_name":"Yuh-Min Chen","normalized_name":"Chen Yuh-Min"},{"full_name":"Heng-sheng Chao","normalized_name":"Chao Heng-sheng"},{"full_name":"Lars Heiliger","normalized_name":"Heiliger Lars"},{"full_name":"Moon Kim","normalized_name":"Kim Moon"},{"full_name":"Johannes Haubold","normalized_name":"Haubold Johannes"},{"full_name":"Frederic Jonske","normalized_name":"Jonske Frederic"},{"full_name":"Pranav Rajpurkar","normalized_name":"Rajpurkar Pranav"}],"summary":"This paper addresses the challenge of evaluating AI-generated radiology reports across diverse hospitals, highlighting the inadequacy of existing metrics in generalizing across different writing styles and patient populations. The authors introduce ReXamine-Global, a novel framework that tests the robustness of report evaluation metrics, revealing significant gaps in their reliability. Empirical findings from 240 reports across six hospitals demonstrate that many established metrics are overly sensitive to stylistic differences, with a new GPT-4-based metric showing superior performance.","weight":0.85,"role":"primary_research","file_path":"pdfs/banerjee-et-al-2024-rexamine-global-a-framework-for-uncovering-inconsistencies-in-radiology-report-generation-metrics.pdf"},{"title":"ReXplain: Translating Radiology into Patient-Friendly Video Reports","authors":[{"full_name":"Luyang Luo","normalized_name":"Luyang Luo"},{"full_name":"Jenanan Vairavamurthy","normalized_name":"Jenanan Vairavamurthy"},{"full_name":"Xiaoman Zhang","normalized_name":"Xiaoman Zhang"},{"full_name":"Abhinav Kumar","normalized_name":"Abhinav Kumar"},{"full_name":"Ramon R. Ter-Oganesyan","normalized_name":"Ramon Ter-Oganesyan"},{"full_name":"Stuart T. Schroff","normalized_name":"Stuart Schroff"},{"full_name":"Dan Shilo","normalized_name":"Dan Shilo"},{"full_name":"Rydhwana Hossain","normalized_name":"Rydhwana Hossain"},{"full_name":"Mike Moritz","normalized_name":"Mike Moritz"},{"full_name":"Pranav Rajpurkar","normalized_name":"Pranav Rajpurkar"}],"summary":"This paper addresses the challenge of making radiology reports comprehensible to patients, who often struggle with complex medical terminology. The key innovation is the ReXplain system, which integrates a large language model for text simplification, an image segmentation model for anatomical identification, and an avatar for delivering explanations. Empirical findings from a proof-of-concept study with five radiologists suggest that ReXplain effectively conveys radiological information and simulates one-on-one consultations, potentially enhancing patient engagement and satisfaction.","weight":0.8,"role":"primary_research","file_path":"pdfs/2410.00441v1.pdf"},{"title":"Randomised controlled trials evaluating artificial intelligence in clinical practice: a scoping review","authors":[{"full_name":"Ryan Han","normalized_name":"Ryan Han"},{"full_name":"Julián N Acosta","normalized_name":"Julian Acosta"},{"full_name":"Zahra Shakeri","normalized_name":"Zahra Shakeri"},{"full_name":"John P A Ioannidis","normalized_name":"John Ioannidis"},{"full_name":"Eric J Topol","normalized_name":"Eric Topol"},{"full_name":"Pranav Rajpurkar","normalized_name":"Pranav Rajpurkar"}],"summary":"This scoping review addresses the growing interest in randomized controlled trials (RCTs) of artificial intelligence (AI) in clinical practice, particularly in the USA and China. The review highlights that 81% of the 86 trials reported positive primary endpoints, mainly in diagnostic yield, but raises concerns about the generalizability of results due to the predominance of single-center studies and limited demographic reporting. It emphasizes the need for multicenter trials and diverse outcome measures to better understand AI's impact on healthcare.","weight":0.8,"role":"primary_research","file_path":"pdfs/PIIS2589750024000475.pdf"}]}]`),i={author:e,introduction:a,topics:n};export{e as author,i as default,a as introduction,n as topics};
